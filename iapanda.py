import streamlit as st
import pandas as pd
import ollama
import subprocess

# ğŸ“Œ Fonction pour rÃ©cupÃ©rer les modÃ¨les installÃ©s dans Ollama
def get_available_models():
    try:
        result = subprocess.run(["ollama", "list"], capture_output=True, text=True)
        if result.returncode == 0:
            models = [line.split()[0] for line in result.stdout.strip().split("\n")[1:]]
            return models
    except Exception:
        return ["llama3", "mistral", "deepseek"]
    return []

# ğŸ“Œ Fonction pour convertir un fichier Excel en Markdown
def excel_to_markdown(file):
    df = pd.read_excel(file, engine='openpyxl')  # Charger le fichier Excel
    return df.to_markdown(index=False)  # Convertir en Markdown

# ğŸ¯ Interface Streamlit
st.set_page_config(page_title="Analyse Excel avec LLaMA", layout="wide")

st.title("ğŸ“Š Analyse de Fichiers Excel avec Ollama")

# ğŸ“‚ TÃ©lÃ©charger un fichier Excel
uploaded_file = st.file_uploader("ğŸ“‚ TÃ©lÃ©chargez un fichier Excel (.xlsx)", type=["xlsx"])

if uploaded_file:
    # ğŸ“Œ Convertir en Markdown
    markdown_data = excel_to_markdown(uploaded_file)

    # ğŸ” Afficher un aperÃ§u des donnÃ©es en Markdown
    st.subheader("ğŸ“œ **DonnÃ©es converties en Markdown :**")
    st.code(markdown_data, language="markdown")

    # ğŸ¯ SÃ©lection du modÃ¨le IA disponible sur Ollama
    available_models = get_available_models()
    selected_model = st.selectbox("ğŸ§  **SÃ©lectionnez un modÃ¨le IA disponible** :", available_models)

    # ğŸ’¬ Demander une question Ã  l'utilisateur
    question = st.text_area("ğŸ’¬ Posez une question Ã  l'IA sur ces donnÃ©es", height=100)

    # ğŸ† Analyser avec LLaMA
    if st.button("ğŸ” Analyser avec lâ€™IA") and question:
        with st.spinner("ğŸ”„ L'IA rÃ©flÃ©chit..."):

            # ğŸ“ Construire le prompt
            prompt = f"""
            Tu es un expert en analyse de donnÃ©es.
            Voici un tableau extrait dâ€™un fichier Excel contenant des informations :

            {markdown_data}

            â“ Question : {question}
            RÃ©ponds en te basant uniquement sur ces donnÃ©es.
            """

            # ğŸ’¡ ExÃ©cuter le modÃ¨le IA sÃ©lectionnÃ©
            response = ollama.chat(model=selected_model, messages=[{"role": "user", "content": prompt}])
            ai_response = response["message"]["content"]

        # ğŸ”¥ Afficher la rÃ©ponse de l'IA
        st.subheader("ğŸ§  **RÃ©ponse de l'IA :**")
        st.write(ai_response)

    # ğŸ¯ Bouton pour rÃ©initialiser la conversation
    if st.button("ğŸ”„ RÃ©initialiser"):
        st.experimental_rerun()
