import streamlit as st
import pandas as pd
import ollama
import tabulate

# ğŸ“Œ Fonction pour convertir un fichier Excel en Markdown
def excel_to_markdown(file):
    df = pd.read_excel(file, engine='openpyxl')  # Charger le fichier Excel
    return df.to_markdown(index=False)  # Convertir en Markdown

# ğŸ¯ Interface Streamlit
st.set_page_config(page_title="Analyse Excel avec LLaMA", layout="wide")

st.title("ğŸ“Š Analyse de Fichiers Excel avec LLaMA")

# ğŸ“‚ TÃ©lÃ©charger un fichier Excel
uploaded_file = st.file_uploader("ğŸ“‚ TÃ©lÃ©chargez un fichier Excel (.xlsx)", type=["xlsx"])

if uploaded_file:
    # ğŸ“Œ Convertir en Markdown
    markdown_data = excel_to_markdown(uploaded_file)

    # ğŸ” Afficher un aperÃ§u des donnÃ©es en Markdown
    st.subheader("ğŸ“œ **DonnÃ©es converties en Markdown :**")
    st.code(markdown_data, language="markdown")

    # ğŸ’¬ Demander une question Ã  l'utilisateur
    question = st.text_area("ğŸ’¬ Posez une question Ã  l'IA sur ces donnÃ©es", height=100)

    # ğŸ† Analyser avec LLaMA
    if st.button("ğŸ” Analyser avec LLaMA") and question:
        with st.spinner("ğŸ”„ L'IA rÃ©flÃ©chit..."):

            # ğŸ“ Construire le prompt
            prompt = f"""
            Tu es un expert en analyse de donnÃ©es.
            Voici un tableau extrait dâ€™un fichier Excel contenant des informations :

            {markdown_data}

            â“ Question : {question}
            RÃ©ponds en te basant uniquement sur ces donnÃ©es.
            """

            # ğŸ’¡ ExÃ©cuter LLaMA
            response = ollama.chat(model="llama3", messages=[{"role": "user", "content": prompt}])
            ai_response = response["message"]["content"]

        # ğŸ”¥ Afficher la rÃ©ponse de LLaMA
        st.subheader("ğŸ§  **RÃ©ponse de LLaMA :**")
        st.write(ai_response)

    # ğŸ¯ Bouton pour rÃ©initialiser la conversation
    if st.button("ğŸ”„ RÃ©initialiser"):
        st.experimental_rerun()
