import pandas as pd
import sqlite3
import chainlit as cl
import subprocess
from pandasai import SmartDataframe
from langchain_community.llms import Ollama
from sqlalchemy import create_engine

# üìå Fonction pour r√©cup√©rer les mod√®les disponibles dans Ollama
def get_available_models():
    try:
        result = subprocess.run(["ollama", "list"], capture_output=True, text=True)
        if result.returncode == 0:
            models = [line.split()[0] for line in result.stdout.strip().split("\n")[1:]]
            return models
    except Exception:
        return ["llama3", "mistral", "deepseek"]
    return []

@cl.on_chat_start
async def start_chat():
    # √âtape 1 : S√©lection du mod√®le IA
    available_models = get_available_models()
    model_select = cl.Select(
        id="model_select",
        label="üß† S√©lectionnez un mod√®le IA",
        values=available_models,
        initial_index=0,
    )
    await model_select.send()

    # Attendre la s√©lection du mod√®le
    settings = await cl.ChatSettings([model_select]).send()
    selected_model = settings["model_select"]

    cl.user_session.set("selected_model", selected_model)

    # √âtape 2 : T√©l√©versement du fichier Excel
    uploaded_file = await cl.AskFileMessage(
        content="üìÇ **T√©l√©versez un fichier Excel √† analyser :**",
        accept=[".xlsx"]
    ).send()

    if uploaded_file:
        # Lire le fichier Excel
        df = pd.read_excel(uploaded_file["path"], engine='openpyxl')

        # Stocker les donn√©es en session
        cl.user_session.set("dataframe", df)

        # √âtape 3 : Cr√©er la base de donn√©es SQLite
        engine = create_engine('sqlite:///database.db')
        df.to_sql("data_table", engine, if_exists="replace", index=False)

        # Afficher un aper√ßu des donn√©es dans l'interface
        preview_message = f"üìä **Aper√ßu des donn√©es (5 premi√®res lignes) :**\n\n{df.head().to_markdown()}"
        await cl.Message(content=preview_message).send()

        await cl.Message(content="‚úÖ **Base de donn√©es cr√©√©e avec succ√®s ! Posez vos questions.**").send()

@cl.on_message
async def main(message: cl.Message):
    # R√©cup√©rer le DataFrame et le mod√®le s√©lectionn√©
    df = cl.user_session.get("dataframe")
    selected_model = cl.user_session.get("selected_model")

    if df is None:
        await cl.Message(content="‚ö†Ô∏è Aucun fichier charg√©. Veuillez t√©l√©verser un fichier Excel.").send()
        return

    # Initialiser l'IA avec le mod√®le s√©lectionn√©
    llm = Ollama(model=selected_model)

    # Convertir le DataFrame en SmartDataframe pour PandasAI
    sdf = SmartDataframe(df, config={"llm": llm})

    # Poser la question √† l'IA
    question = message.content
    response = sdf.chat(question)

    await cl.Message(content=response).send()
